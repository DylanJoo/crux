---
tag: testing-gen
model_tag: llama-3.1-8b
load_mode: vllm
batch_size: 32
max_length: 8192
ampere_gpu: True
multi_news_file: ~/datasets/multi_news
split: test
model: meta-llama/Llama-3.1-8B-Instruct
batch_size: 2
temperature: 0.7
top_p: 0.95
max_new_tokens: 640
num_gpus: 1
output_dir: ~/datasets/crux/shard_data/
