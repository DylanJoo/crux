---
tag: default-gen
model: meta-llama/Llama-3.3-70B-Instruct
model_tag: llama-3.3-70b
load_mode: vllm
batch_size: 1
temperature: 0
top_p: 1.0
max_new_tokens: 64
max_length: 8192
ampere_gpu: True
num_gpus: 1
