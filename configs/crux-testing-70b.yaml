---
tag: testing-gen
model_tag: llama-3.3-70b
load_mode: vllm
batch_size: 1
max_length: 8192
ampere_gpu: True
multi_news_file: ~/datasets/multi_news
split: test
model: meta-llama/Llama-3.3-70B-Instruct
batch_size: 2
temperature: 0.7
top_p: 0.95
max_new_tokens: 640
num_gpus: 4
output_dir: ~/datasets/crux/shard_data/
